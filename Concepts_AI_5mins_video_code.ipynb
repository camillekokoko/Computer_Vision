{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8h9O90OBaJV_",
        "outputId": "be5b07e1-231d-4967-aab4-e88ba09901bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch Version : 1.12.1+cu113\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "print(\"PyTorch Version : {}\".format(torch.__version__))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTbuwSfbaLSe",
        "outputId": "1f187d7f-fe85-4097-9375-5c95cf2ae2ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TorchVision Version : 0.13.1+cu113\n"
          ]
        }
      ],
      "source": [
        "import torchvision\n",
        "\n",
        "print(\"TorchVision Version : {}\".format(torchvision.__version__))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Xrv-wQZaTcV"
      },
      "outputs": [],
      "source": [
        "import pycocotools\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision.transforms.functional import pil_to_tensor\n",
        "from torchvision.utils import draw_bounding_boxes\n",
        "from torchvision.transforms.functional import to_pil_image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c-uB0PYm4k4",
        "outputId": "50e7a1e9-0f21-4859-cf08-f10f0326776d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-11-16 02:55:13--  http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 54.231.162.233\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|54.231.162.233|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 252907541 (241M) [application/zip]\n",
            "Saving to: ‘annotations_trainval2017.zip.1’\n",
            "\n",
            "annotations_trainva 100%[===================>] 241.19M  82.0MB/s    in 2.9s    \n",
            "\n",
            "2022-11-16 02:55:16 (82.0 MB/s) - ‘annotations_trainval2017.zip.1’ saved [252907541/252907541]\n",
            "\n",
            "Archive:  annotations_trainval2017.zip\n",
            "replace annotations/instances_train2017.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace annotations/instances_val2017.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace annotations/captions_train2017.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace annotations/captions_val2017.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace annotations/person_keypoints_train2017.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
        "!unzip annotations_trainval2017.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKpVtlxgm54X"
      },
      "outputs": [],
      "source": [
        "from pycocotools.coco import COCO\n",
        "\n",
        "annFile='annotations/instances_val2017.json'\n",
        "\n",
        "coco=COCO(annFile)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpDgNxd6iK36"
      },
      "source": [
        "# 1. Load Image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tK1zo8giZkF"
      },
      "outputs": [],
      "source": [
        "def load_image(path):\n",
        "  img = Image.open(path)\n",
        "  width, height = img.size\n",
        "  print(width, height)\n",
        "  return img\n",
        "\n",
        "def preproces(img):\n",
        "  img_tensor_int = pil_to_tensor(img)\n",
        "  img_tensor_int = img_tensor_int.unsqueeze(dim=0)\n",
        "  img_tensor_float = img_tensor_int / 255.0\n",
        "  return img_tensor_int, img_tensor_float\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Npgr35nslLW7"
      },
      "outputs": [],
      "source": [
        "# cm_far = load_image(\"/content/faraway_centralmarket.jpeg\") #multiclass\n",
        "# cm_far_tehuge_ppl = load_image(\"/content/huge_people.jpeg\") #very high resolution\n",
        "# huge_ppl_tensor_int, huge_ppl_tensor_float = preproces(huge_ppl)\n",
        "# huge_pplnsor_int, cm_far_tensor_float = preproces(cm_far)\n",
        "# cm_far"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNg4PjaVl36E"
      },
      "outputs": [],
      "source": [
        "# cm_close = load_image(\"/content/market-img2.jpeg\") #multiclass\n",
        "# cm_close_tensor_int, cm_close_tensor_float = preproces(cm_close)\n",
        "# cm_close"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtAGET5MmEqh"
      },
      "outputs": [],
      "source": [
        "# huge_ppl = load_image(\"/content/huge_people.jpeg\") #very high resolution\n",
        "# huge_ppl_tensor_int, huge_ppl_tensor_float = preproces(huge_ppl)\n",
        "# huge_ppl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "f6E18uW7mLG7"
      },
      "outputs": [],
      "source": [
        "# small_ppl = load_image(\"/content/small_people.jpeg\") #very high resolution\n",
        "# small_ppl_tensor_int, small_ppl_tensor_float = preproces(small_ppl)\n",
        "# small_ppl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3kRZ9_dBS7Wo"
      },
      "outputs": [],
      "source": [
        "# cm1 = load_image(\"/content/cm1.jpeg\") #very high resolution\n",
        "# cm1_tensor_int, cm1_tensor_float = preproces(cm1)\n",
        "# cm1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cd1O-xkXTDgP"
      },
      "outputs": [],
      "source": [
        "# cm2 = load_image(\"/content/kina-QTYROea8lWs-unsplash.jpeg\") #very high resolution\n",
        "# cm2_tensor_int, cm2_tensor_float = preproces(cm2)\n",
        "# cm2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3gzxww_vVVdK"
      },
      "outputs": [],
      "source": [
        "# cm3 = load_image(\"/content/kina-jchwccyZuhI-unsplash.jpeg\") #very high resolution\n",
        "# cm3_tensor_int, cm3_tensor_float = preproces(cm3)\n",
        "# cm3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eN6ST-6wZE1F"
      },
      "outputs": [],
      "source": [
        "# cm4 = load_image(\"/content/kina-jchwccyZuhI-unsplash.jpeg\") #very high resolution\n",
        "# cm4_tensor_int, cm4_tensor_float = preproces(cm4)\n",
        "# cm4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qQ3rmys-aCgM"
      },
      "outputs": [],
      "source": [
        "# cm5 = load_image(\"/content/45864770764_807afc5ef2_k.jpeg\") #very high resolution\n",
        "# cm5_tensor_int, cm5_tensor_float = preproces(cm5)\n",
        "# cm5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRVqdPVWjEp3"
      },
      "source": [
        "# 2. Load Pre-Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "W9trvelKhSBl",
        "outputId": "ced12c84-6186-44ce-f39c-d043dcd4db78"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=SSD300_VGG16_Weights.COCO_V1`. You can also use `weights=SSD300_VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn,ssd300_vgg16\n",
        "\n",
        "frnn_model = fasterrcnn_resnet50_fpn(pretrained=True, progress=False)\n",
        "ssd_model = ssd300_vgg16(pretrained=True, progress=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BfCuFHgUnSqu"
      },
      "outputs": [],
      "source": [
        "def pred(img_tensor_float, th, algo):\n",
        "  if algo == \"FRNN\":\n",
        "    frnn_model.eval(); ## Setting Model for Evaluation/Prediction\n",
        "\n",
        "    img_preds = frnn_model(img_tensor_float)\n",
        "    img_preds[0][\"boxes\"] = img_preds[0][\"boxes\"][img_preds[0][\"scores\"] > th]\n",
        "    img_preds[0][\"labels\"] = img_preds[0][\"labels\"][img_preds[0][\"scores\"] > th]\n",
        "    img_preds[0][\"scores\"] = img_preds[0][\"scores\"][img_preds[0][\"scores\"] > th]\n",
        "    # Map Target Category Ids to Labels\n",
        "    img_labels = coco.loadCats(img_preds[0][\"labels\"].numpy())\n",
        "\n",
        "  elif algo == \"SSD\": \n",
        "    ssd_model.eval(); ## Setting Model for Evaluation/Prediction\n",
        "\n",
        "    img_preds = ssd_model(img_tensor_float)\n",
        "    img_preds[0][\"boxes\"] = img_preds[0][\"boxes\"][img_preds[0][\"scores\"] > th]\n",
        "    img_preds[0][\"labels\"] = img_preds[0][\"labels\"][img_preds[0][\"scores\"] > th]\n",
        "    img_preds[0][\"scores\"] = img_preds[0][\"scores\"][img_preds[0][\"scores\"] > th]\n",
        "    # Map Target Category Ids to Labels\n",
        "    img_labels = coco.loadCats(img_preds[0][\"labels\"].numpy())\n",
        "  return img_labels,img_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Zx3chtgan-Ta"
      },
      "outputs": [],
      "source": [
        "def bounding_box(img,th=0.8,algo=\"FRNN\"): #\"FRNN | SSD\"\n",
        "  img_tensor_int, img_tensor_float = preproces(img)\n",
        "  img_labels, img_preds = pred(img_tensor_float,th,algo)\n",
        "  img_annot_labels = [\"{}-{:.2f}\".format(label[\"name\"], prob) for label, prob in zip(img_labels, img_preds[0][\"scores\"].detach().numpy())]\n",
        "\n",
        "  img_output = draw_bounding_boxes(image=img_tensor_int[0],\n",
        "                             boxes=img_preds[0][\"boxes\"],\n",
        "                             labels=img_annot_labels,\n",
        "                             colors=[\"red\" if label[\"name\"]==\"person\" else \"green\" for label in img_labels],\n",
        "                             width=2\n",
        "                            )\n",
        "  print(img_output.shape)\n",
        "  return to_pil_image(img_output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "W70_99Yu2kli"
      },
      "outputs": [],
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def show(img, figsize):\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize=figsize, dpi=80)\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)), interpolation='nearest')\n",
        "    plt.show()\n",
        "\n",
        "def bounding_box_plt(img,th=0.8,algo=\"FRNN\", size=(10,10)): #\"FRNN | SSD\"\n",
        "  img_tensor_int, img_tensor_float = preproces(img)\n",
        "  img_labels, img_preds = pred(img_tensor_float,th,algo)\n",
        "  img_annot_labels = [\"{}-{:.2f}\".format(label[\"name\"], prob) for label, prob in zip(img_labels, img_preds[0][\"scores\"].detach().numpy())]\n",
        "\n",
        "  img_output = draw_bounding_boxes(image=img_tensor_int[0],\n",
        "                             boxes=img_preds[0][\"boxes\"],\n",
        "                             labels=img_annot_labels,\n",
        "                             colors=[\"red\" if label[\"name\"]==\"person\" else \"green\" for label in img_labels],\n",
        "                             width=2\n",
        "                            )\n",
        "  print(img_output.shape)\n",
        "  return show(img_output, figsize=size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCXNI9k1m2bk"
      },
      "source": [
        "# 3. Visualize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "41-Yg4wdTIsM"
      },
      "outputs": [],
      "source": [
        "# cm1_output_ssd = bounding_box(cm1,th=0.7,algo=\"SSD\")\n",
        "# cm1_output_ssd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Z6_CB9flTSgC"
      },
      "outputs": [],
      "source": [
        "# cm1_output_frnn = bounding_box(cm1,th=0.7,algo=\"FRNN\")\n",
        "# cm1_output_frnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "CAFUplSgTQOD"
      },
      "outputs": [],
      "source": [
        "# cm2_output_frnn = bounding_box(cm2,th=0.7,algo=\"FRNN\")\n",
        "# cm2_output_frnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5sLoKpJTWj8a"
      },
      "outputs": [],
      "source": [
        "# cm2_output_ssd = bounding_box_plot(cm2,th=0.7,algo=\"SSD\")\n",
        "# cm2_output_ssd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5IDCDWdEaliQ"
      },
      "outputs": [],
      "source": [
        "# cm5_output_frnn = bounding_box(cm5,th=0.7,algo=\"FRNN\")\n",
        "# cm5_output_frnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "8L9vP8Puawso"
      },
      "outputs": [],
      "source": [
        "# cm5_output_ssd = bounding_box(cm5,th=0.7,algo=\"SSD\")\n",
        "# cm5_output_ssd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MoNXn0upVgXv"
      },
      "outputs": [],
      "source": [
        "# cm3_output_frnn = bounding_box(cm3,th=0.7,algo=\"FRNN\")\n",
        "# cm3_output_frnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dmrRf32VVkdl"
      },
      "outputs": [],
      "source": [
        "# cm3_output_ssd = bounding_box(cm3,th=0.7,algo=\"SSD\")\n",
        "# cm3_output_ssd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DQHI8y-IV2cz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "62ea30a7td9X"
      },
      "outputs": [],
      "source": [
        "# cm_close_output_ssd = bounding_box_plt(cm_close,th=0.7,algo=\"SSD\", size=(10,10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sIDCqe8Qz0Y2"
      },
      "outputs": [],
      "source": [
        "# cm_close_output_frnn = bounding_box_plt(cm_close,th=0.7,algo=\"FRNN\", size=(10,10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0s4r66wDxFfC"
      },
      "outputs": [],
      "source": [
        "# cm_far_output_ssd = bounding_box_plt(cm_far,th=0.7,algo=\"SSD\", size=(10,10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vOBnnL501T_b"
      },
      "outputs": [],
      "source": [
        "# cm_far_output_frnn = bounding_box_plt(cm_far,th=0.7,algo=\"FRNN\", size=(10,10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mbLQBlPO1YTZ"
      },
      "outputs": [],
      "source": [
        "# huge_ppl_output_frnn = bounding_box_plt(huge_ppl,th=0.7,algo=\"FRNN\", size=(10,10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oREUii0F1es7"
      },
      "outputs": [],
      "source": [
        "# huge_ppl_output_ssd = bounding_box_plt(huge_ppl,th=0.7,algo=\"SSD\", size=(10,10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "T_eLmw2z1slb"
      },
      "outputs": [],
      "source": [
        "# small_ppl_output_frnn = bounding_box(small_ppl,th=0.7,algo=\"FRNN\")\n",
        "# small_ppl_output_frnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "X1UENmnQ1gBe"
      },
      "outputs": [],
      "source": [
        "# small_ppl_output_ssd = bounding_box(small_ppl,th=0.7,algo=\"SSD\")\n",
        "# small_ppl_output_ssd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "adnMuwMv2BGY"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "\n",
        "# # Model\n",
        "# model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
        "# model.conf=0.6\n",
        "# # # Image\n",
        "# # img = cv2.imread(\"/content/centra.webp\") # Read image with cv2\n",
        "# # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) \n",
        "# # # im = 'https://ultralytics.com/images/zidane.jpg'\n",
        "\n",
        "# # Inference\n",
        "# results = model(small_ppl)\n",
        "\n",
        "# results.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pYnBz4ChMmCV"
      },
      "outputs": [],
      "source": [
        "# results = model(huge_ppl)\n",
        "\n",
        "# results.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xg_m0cbwMxAr"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}